{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@author Adrian Spork\n",
    "#@author Tatjana Melina Walter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentinelsat import SentinelAPI, read_geojson, geojson_to_wkt\n",
    "import geopandas as gpd\n",
    "import getpass\n",
    "import xarray as xr\n",
    "import rasterio as rio\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import shutil\n",
    "from time import sleep\n",
    "import stat\n",
    "import io\n",
    "from rasterio.enums import Resampling\n",
    "import netCDF4 as nc\n",
    "from datetime import datetime\n",
    "from zipfile import ZipFile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def downloadingData(aoi, collectionDate, plName, prLevel, clouds, username, password, directory):\n",
    "    '''\n",
    "    Downloads the Sentinel2 - Data with the given parameters\n",
    "\n",
    "    Parameters:\n",
    "        aoi (str): The type and the coordinates of the area of interest\n",
    "        collectionDate datetime 64[ns]): The date of the data\n",
    "        plName (str): The name of the platform\n",
    "        prLevel (str): The name of the process\n",
    "        clouds (tuple of ints): Min and max of cloudcoverpercentage\n",
    "        username (str): The username of the Copernicus SciHub\n",
    "        password (str): The password of the Copernicus SciHub\n",
    "        directory (str): Pathlike string to the directory\n",
    "    '''\n",
    "    \n",
    "    api = SentinelAPI(username, password, 'https://scihub.copernicus.eu/dhus')\n",
    "    \n",
    "    '''Choosing the data with bounding box (footprint), date, platformname, processinglevel and cloudcoverpercentage'''\n",
    "    products = api.query(aoi, date = collectionDate, platformname = plName, processinglevel = prLevel, cloudcoverpercentage = clouds)\n",
    "\n",
    "    '''Filters the products and sorts by cloudcoverpercentage'''\n",
    "    products_gdf = api.to_geodataframe(products)\n",
    "    products_gdf_sorted = products_gdf.sort_values(['cloudcoverpercentage'], ascending = [True])\n",
    "\n",
    "    '''Downloads the choosen files from Scihub'''\n",
    "    products_gdf_sorted.to_csv(os.path.join(directory, 'w'))\n",
    "    api.download_all(products, directory, max_attempts = 10, checksum = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unzipping(filename, directory):\n",
    "    '''\n",
    "    Unzips the file with the given filename\n",
    "\n",
    "    Parameter:\n",
    "        filename(str): Name of the .zip file\n",
    "        directory (str): Pathlike string to the directory\n",
    "    '''\n",
    "    with ZipFile(os.path.join(directory, filename), 'r') as zipObj:\n",
    "        zipObj.extractall(directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unzip(directory):\n",
    "    '''\n",
    "    Unzips and deletes the .zip in the given directory\n",
    "\n",
    "    Parameters:\n",
    "        directory (str): Pathlike string to the directory\n",
    "    '''\n",
    "\n",
    "    for filename in os.listdir(directory):\n",
    "        if filename.endswith(\".zip\"):\n",
    "            if(filename[39:41]!=\"32\"):\n",
    "                print(\"CRS not supported! Only EPSG:32632 supported\") #do not throw an exception here\n",
    "                delete(os.path.join(directory,filename))\n",
    "            else:\n",
    "                unzipping(filename, directory)\n",
    "                delete(os.path.join(directory, filename))\n",
    "                continue\n",
    "        else:\n",
    "            continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def delete(path):\n",
    "    '''\n",
    "    Deletes the file/directory with the given path\n",
    "\n",
    "    Parameters:\n",
    "        path (str): Path to the file/directory\n",
    "    '''\n",
    "\n",
    "    if os.path.exists(path):\n",
    "        os.remove(path)\n",
    "        print(\"File deleted: \" + path)\n",
    "    else:\n",
    "        print(\"The file does not exist\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extractBands(filename, resolution, directory):\n",
    "    '''\n",
    "    Extracts bandpaths from the given .SAFE file\n",
    "\n",
    "    Parameters:\n",
    "        filename (str): Sentinel .SAFE file\n",
    "        resolution (int): The resolution the datacube should have\n",
    "        directory (str): Pathlike string to the directory\n",
    "\n",
    "    Returns:\n",
    "        bandPaths (str[]): An array of the paths for the red and nir band\n",
    "    '''\n",
    "\n",
    "    lTwoA = os.listdir(os.path.join(directory, filename, \"GRANULE\"))\n",
    "\n",
    "    if resolution == 10:\n",
    "        bandName = os.listdir (os.path.join(directory, filename, \"GRANULE\", str(lTwoA[0]), \"IMG_DATA\", \"R10m\"))\n",
    "        pathRed = os.path.join(directory, filename, \"GRANULE\", str(lTwoA[0]), \"IMG_DATA\", \"R10m\", str(bandName[3]))\n",
    "        pathNIR = os.path.join(directory, filename, \"GRANULE\", str(lTwoA[0]), \"IMG_DATA\", \"R10m\", str(bandName[4]))\n",
    "        bandPaths = [pathRed, pathNIR]\n",
    "\n",
    "    elif resolution == 20:\n",
    "        bandName = os.listdir (os.path.join(directory, filename, \"GRANULE\", str(lTwoA[0]), \"IMG_DATA\", \"R20m\"))\n",
    "        pathRed = os.path.join(directory, filename, \"GRANULE\", str(lTwoA[0]), \"IMG_DATA\", \"R20m\", str(bandName[3]))\n",
    "        pathNIR = os.path.join(directory, filename, \"GRANULE\", str(lTwoA[0]), \"IMG_DATA\", \"R20m\", str(bandName[9]))\n",
    "        bandPaths = [pathRed, pathNIR]\n",
    "\n",
    "    elif resolution == 60:\n",
    "        bandName = os.listdir (os.path.join(directory, filename, \"GRANULE\", str(lTwoA[0]), \"IMG_DATA\", \"R60m\"))\n",
    "        pathRed = os.path.join(directory, filename, \"GRANULE\", str(lTwoA[0]), \"IMG_DATA\", \"R60m\", str(bandName[4]))\n",
    "        pathNIR = os.path.join(directory, filename, \"GRANULE\", str(lTwoA[0]), \"IMG_DATA\", \"R60m\", str(bandName[11]))\n",
    "        bandPaths = [pathRed, pathNIR]\n",
    "\n",
    "    elif resolution == 100:\n",
    "        bandName = os.listdir (os.path.join(directory, filename, \"GRANULE\", str(lTwoA[0]), \"IMG_DATA\", \"R20m\"))\n",
    "        pathRed = os.path.join(directory, filename, \"GRANULE\", str(lTwoA[0]), \"IMG_DATA\", \"R20m\", str(bandName[3]))\n",
    "        pathNIR = os.path.join(directory, filename, \"GRANULE\", str(lTwoA[0]), \"IMG_DATA\", \"R20m\", str(bandName[9]))\n",
    "        bandPaths = [pathRed, pathNIR]\n",
    "\n",
    "    else:\n",
    "        print(\"No such resolution\")\n",
    "        return -1\n",
    "\n",
    "    return bandPaths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadBand (bandpath, date, tile, resolution, clouds, plName, prLevel, directory):\n",
    "    '''\n",
    "    Opens and reads the red and nir band, saves them as NetCDF file\n",
    "\n",
    "    Parameters:\n",
    "        bandPaths (str[]): Array with the paths to the red and nir band\n",
    "        date (datetime 64[ns]): The collection date (\"2020-12-31\")\n",
    "        tile (str): Bounding box of coordinates defined by Sentinel\n",
    "        resolution (int): The resolution of the dataset\n",
    "        clouds (tuple of ints): Min and max of cloudcoverpercentage\n",
    "        plName (str): The name of the platform\n",
    "        prLevel (str): The level of the process\n",
    "        directory (str): Pathlike string to the directory\n",
    "\n",
    "    Returns:\n",
    "        dataset (xArray dataset): The result dataset as xArray dataset\n",
    "    '''\n",
    "\n",
    "    b4 = rio.open(bandpath[0])\n",
    "    b8 = rio.open(bandpath[1])\n",
    "    red = b4.read()\n",
    "    nir = b8.read()\n",
    "\n",
    "    if resolution == 10:\n",
    "        res = 1830 * 3 * 2\n",
    "    elif resolution == 20:\n",
    "        res = 1830 * 3\n",
    "    elif resolution == 60:\n",
    "        res = 1830\n",
    "    elif resolution == 100:\n",
    "        res = 1098\n",
    "    else:\n",
    "        print(\"No such resolution\")\n",
    "        return -1\n",
    "\n",
    "    j = res - 1\n",
    "    i = 0\n",
    "    lat = [0] * res\n",
    "    lon = [0] * res\n",
    "    while j >= 0:\n",
    "        lon[i] = b4.bounds.left + i * resolution\n",
    "        lat[i] = b4.bounds.bottom + j * resolution\n",
    "        i = i + 1\n",
    "        j = j - 1\n",
    "\n",
    "    time = pd.date_range(date, periods = 1)\n",
    "\n",
    "    if resolution == 100:\n",
    "        upscale_factor = (1/5)\n",
    "        nir = b8.read(\n",
    "                out_shape = (\n",
    "                    b8.count,\n",
    "                    int(b8.height * upscale_factor),\n",
    "                    int(b8.width * upscale_factor)\n",
    "                ),\n",
    "                resampling = Resampling.bilinear\n",
    "        )\n",
    "        transform = b8.transform * b8.transform.scale(\n",
    "            (b8.width / nir.shape[-1]),\n",
    "            (b8.height / nir.shape[-2])\n",
    "        )\n",
    "        red = b4.read(\n",
    "            out_shape = (\n",
    "                b4.count,\n",
    "                int(b4.height * upscale_factor),\n",
    "                int(b4.width * upscale_factor)\n",
    "            ),\n",
    "            resampling = Resampling.bilinear\n",
    "        )\n",
    "\n",
    "        transform = b4.transform * b4.transform.scale(\n",
    "            (b4.width / red.shape[-1]),\n",
    "            (b4.height / red.shape[-2])\n",
    "        )\n",
    "\n",
    "    dataset = xr.Dataset(\n",
    "        {\n",
    "            \"red\": ([\"time\",\"lat\", \"lon\"], red),\n",
    "            \"nir\": ([\"time\",\"lat\", \"lon\"], nir)\n",
    "        },\n",
    "        coords = dict(\n",
    "            time = time,\n",
    "            lat = ([\"lat\"], lat),\n",
    "            lon = ([\"lon\"], lon),\n",
    "        ),\n",
    "        attrs = dict(\n",
    "            platform = plName,\n",
    "            processingLevel = prLevel,\n",
    "            cloudcover = clouds,\n",
    "            source = \"https://scihub.copernicus.eu/dhus\",\n",
    "            resolution = str(resolution) + \" x \" + str(resolution) + \" m\"\n",
    "        ),\n",
    "    )\n",
    "\n",
    "    dataset.to_netcdf(directory + \"datacube_\" + str(date) + \"_\" + str(tile) + \"_R\" + str(resolution) + \".nc\", 'w', format = 'NETCDF4')\n",
    "    b4.close()\n",
    "    b8.close()\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getDate(filename):\n",
    "    '''\n",
    "    Extracts the Date out of the Sentinelfilename\n",
    "\n",
    "    Parameters:\n",
    "        filename (str): Name of the file\n",
    "\n",
    "    Returns:\n",
    "        (str): Date of the File (\"2020-12-31\")\n",
    "    '''\n",
    "\n",
    "    return filename[11:15] + \"-\" + filename[15:17] + \"-\" + filename[17:19]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getTile(filename):\n",
    "    '''\n",
    "    Extracts the UTM-tile of the Sentinelfilename\n",
    "\n",
    "    Parameters:\n",
    "        filename (str): Name of the file\n",
    "\n",
    "    Returns:\n",
    "        (str): UTM-tile of the File (\"32UMC\")\n",
    "    '''\n",
    "    return filename[38:44]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def on_rm_error(func, path, exc_info):\n",
    "    '''\n",
    "    Unlinks a read-only file\n",
    "    '''\n",
    "\n",
    "    os.chmod(path, stat.S_IWRITE)\n",
    "    os.unlink(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def buildCube(directory, resolution, clouds, plName, prLevel):\n",
    "    '''\n",
    "    Builds a datacube in the given directory with coords, time as dimensions and the bands as datavariables\n",
    "\n",
    "    Parameters:\n",
    "        directory (str): Pathlike string to the directory\n",
    "        resolution (int): The resolution of the dataset\n",
    "        clouds (tuple of ints): Min and max of cloudcoverpercentage\n",
    "        plName (str): The name of the platform\n",
    "        prLevel (str): The level of the process\n",
    "    '''\n",
    "\n",
    "    for filename in os.listdir(directory):\n",
    "        if filename.endswith(\".SAFE\"):\n",
    "            bandPath = extractBands(os.path.join(directory, filename), resolution, directory)\n",
    "            band = loadBand(bandPath, getDate(filename), getTile(filename), resolution, clouds, plName, prLevel, directory)\n",
    "            shutil.rmtree(os.path.join(directory, filename), onerror = on_rm_error)\n",
    "            continue\n",
    "        else:\n",
    "            continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "def merge_Sentinel(directory):\n",
    "    '''\n",
    "    Merges datacubes by coordinates and time\n",
    "\n",
    "    Parameters:\n",
    "        directory (str): Pathlike string where Data is stored\n",
    "    '''\n",
    "\n",
    "    start = datetime.now()\n",
    "    count1 = 0\n",
    "    files = os.listdir(directory)\n",
    "\n",
    "    if len(files) == 0:\n",
    "        print(\"Directory empty\")\n",
    "        return\n",
    "    elif len(files) == 1:\n",
    "        print(\"Only one file in directory\")\n",
    "        return\n",
    "    else:\n",
    "        print('Start merging')\n",
    "        for file1 in files:\n",
    "            if count1 == len(files):\n",
    "                return\n",
    "            for file2 in files:\n",
    "                count2 = 0\n",
    "                if file1.endswith(\".nc\") and file2.endswith(\".nc\"):\n",
    "                    file1Date = file1[9:19]\n",
    "                    file1Tile = file1[20:26]\n",
    "                    file1Res = file1[27:31]\n",
    "                    file2Date = file2[9:19]\n",
    "                    file2Tile = file2[20:26]\n",
    "                    file2Res = file2[27:31]\n",
    "                    if file1[21:23] == \"31\":\n",
    "                        delete(os.path.join(directory,file1))\n",
    "                    elif file2[21:23] == \"31\":\n",
    "                        delete(os.path.join(directory,file2))\n",
    "                    elif file1Date == file2Date and file1Tile == file2Tile and file1Res == file2Res:\n",
    "                        continue\n",
    "                    elif file1Date == file2Date and file1Tile == \"T32ULC\" and file2Tile == \"T32UMC\" and file1Res == file2Res:\n",
    "                        fileLeft = xr.open_dataset(os.path.join(directory, file1))\n",
    "                        fileRight = xr.open_dataset(os.path.join(directory, file2))\n",
    "                        merge_coords(fileLeft, fileRight, file1[0:20] + \"Merged\" + file1[26:31], directory)\n",
    "                        fileLeft.close()\n",
    "                        fileRight.close()\n",
    "                        delete(os.path.join(directory, file1))\n",
    "                        delete(os.path.join(directory, file2))\n",
    "                        continue\n",
    "                else:\n",
    "                    raise TypeError(\"Wrong file in directory\") \n",
    "                    \n",
    "\n",
    "        files = os.listdir(directory)\n",
    "        while len(os.listdir(directory)) > 1:\n",
    "            files = os.listdir(directory)\n",
    "            if files[0].endswith(\".nc\") and files[1].endswith(\".nc\"):\n",
    "                file1 = xr.open_dataset(os.path.join(directory, files[0]))\n",
    "                file2 = xr.open_dataset(os.path.join(directory, files[1]))\n",
    "                merge_time(file1, file2, files[0][0:31], directory)\n",
    "                file1.close()\n",
    "                file2.close()\n",
    "                delete(os.path.join(directory, files[1]))\n",
    "                continue\n",
    "            else:\n",
    "                print(\"Error: Wrong file in directory\")\n",
    "                raise TypeError(\"Wrong file in directory\") \n",
    "\n",
    "    end = datetime.now()\n",
    "    diff = end - start\n",
    "    print('All cubes merged for ' + str(diff.seconds) + 's')\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def timeframe(ds, start, end):\n",
    "    '''\n",
    "    Slices Datacube down to given timeframe\n",
    "\n",
    "    Parameters:\n",
    "        ds (xArray Dataset): Sourcedataset\n",
    "        start (str): Start of the timeframe eg '2018-07-13'\n",
    "        end (str): End of the timeframe eg '2018-08-23'\n",
    "\n",
    "    Returns:\n",
    "        ds_selected (xArray Dataset): Dataset sliced to timeframe\n",
    "    '''\n",
    "\n",
    "    if start > end:\n",
    "        print(\"start and end of the timeframe are not compatible!\")\n",
    "    else:\n",
    "        ds_selected = ds.sel(time = slice(start, end))\n",
    "        return ds_selected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def safe_datacube(ds, name, directory):\n",
    "    '''\n",
    "    Saves the Datacube as NetCDF (.nc)\n",
    "\n",
    "    Parameters:\n",
    "        ds (xArray Dataset): Sourcedataset\n",
    "        name (str): Name eg '2017', '2015_2019'\n",
    "        directory (str): Pathlike string to the directory\n",
    "    '''\n",
    "\n",
    "    print(\"Start saving\")\n",
    "    start = datetime.now()\n",
    "    if type(name) != str:\n",
    "        name = str(name)\n",
    "    ds.to_netcdf(directory + name + \".nc\")\n",
    "    diff = datetime.now() - start\n",
    "    print(\"Done saving after \"+ str(diff.seconds) + 's')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_coords(ds_left, ds_right, name, directory):\n",
    "    '''\n",
    "    Merges two datasets by coordinates\n",
    "\n",
    "    Parameters:\n",
    "        ds_left (xArray dataset): Dataset to be merged\n",
    "        ds_right (xArray dataset): Dataset to be merged\n",
    "        name (str): Name of the new dataset\n",
    "        directory (str): Pathlike string to the directory\n",
    "    '''\n",
    "\n",
    "    ds_selected = slice_lon(ds_left, ds_left.lon[0], ds_right.lon[0])\n",
    "    ds_merge = [ds_selected, ds_right]\n",
    "    merged = xr.combine_by_coords(ds_merge)\n",
    "    safe_datacube(merged, name, directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_time(ds1, ds2, name, directory):\n",
    "    '''\n",
    "    Merges two datasets by time\n",
    "\n",
    "    Parameters:\n",
    "        ds1 (xArray dataset): Dataset to be merged\n",
    "        ds2 (xArray dataset): Dataset to be merged\n",
    "        name (str): Name of the new dataset\n",
    "        directory (str): Pathlike string to the directory\n",
    "    '''\n",
    "\n",
    "    res = xr.combine_by_coords([ds1, ds2])\n",
    "    ds1.close()\n",
    "    ds2.close()\n",
    "    safe_datacube(res, name, directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def slice_lat(ds, lat_left, lat_right):\n",
    "    '''\n",
    "    Slices a given dataset to given latitude bounds\n",
    "\n",
    "    Parameters:\n",
    "        ds (xArray Dataset): Dataset to be sliced\n",
    "        lat_left (float): Left latitude bound\n",
    "        lat_right (float): Right latitude bound\n",
    "\n",
    "    Returns:\n",
    "        ds (xArray Dataset): Sliced dataset\n",
    "    '''\n",
    "\n",
    "    ds_selected = ds.sel(lat = slice(lat_left, lat_right))\n",
    "    return ds_selected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def slice_lon(ds, lon_left, lon_right):\n",
    "    '''\n",
    "    Slices a given dataset to given longitude bounds\n",
    "\n",
    "    Parameters:\n",
    "        ds (xArray Dataset): Dataset to be sliced\n",
    "        lon_left (float): Left longitude bound\n",
    "        lon_right (float): Right longitude bound\n",
    "\n",
    "    Returns:\n",
    "        ds (xArray Dataset): Sliced dataset\n",
    "    '''\n",
    "\n",
    "    ds_selected = ds.sel(lon = slice(lon_left, lon_right))\n",
    "    return ds_selected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def slice_coords(ds, lon_left, lon_right, lat_left, lat_right):\n",
    "    '''\n",
    "    Slices a dataset to a given slice\n",
    "\n",
    "    Parameters:\n",
    "        ds (xArray Dataset): Dataset to be sliced\n",
    "        lon_left (float): Left bound for longitude\n",
    "        lon_right (float): Right bound for longitude\n",
    "        lat_left (float): Left bound for latitude\n",
    "        lat_right (float): Right bound for latitude\n",
    "\n",
    "    Returns:\n",
    "        ds (xArray Dataset): Sliced dataset\n",
    "    '''\n",
    "\n",
    "    ds_selected = slice_lon(ds, lon_left, lon_right)\n",
    "    return slice_lat(ds_selected, lat_left, lat_right)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mainSentinel(resolution, directory, collectionDate, aoi, clouds, username, password):\n",
    "    '''\n",
    "    Downloads, unzips, collects and merges Sentinel2 Satelliteimages to a single netCDF4 datacube\n",
    "\n",
    "    Parameters:\n",
    "        resolution (int): Resolution of the satelite image\n",
    "        directory (str): Pathlike string to the workdirectory\n",
    "        collectionDate (tuple of datetime 64[ns]): Start and end of the timeframe\n",
    "        aoi (POLYGON): Area of interest\n",
    "        clouds (tuple of ints): Min and max of cloudcoverpercentage\n",
    "        username (str): Uername for the Copernicus Open Acess Hub\n",
    "        password (str): Password for the Copernicus Open Acess Hub\n",
    "    '''\n",
    "\n",
    "    plName = 'Sentinel-2'\n",
    "    prLevel = 'Level-2A'\n",
    "    downloadingData (aoi, collectionDate, plName, prLevel, clouds, username, password, directory)\n",
    "    delete(os.path.join(directory,'w'))\n",
    "    unzip(directory)\n",
    "    buildCube(directory, resolution, clouds, plName, prLevel)\n",
    "    merge_Sentinel(directory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user: ········\n",
      "password: ········\n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      "Start merging\n",
      "Start saving\n",
      "Done saving after 0s\n",
      "File deleted: C:/Users/adria/Desktop/Uni/Semester5/Geosoft2/Code/Notebooks/Sentinel/Data/datacube_2020-06-01_T32ULC_R100.nc\n",
      "File deleted: C:/Users/adria/Desktop/Uni/Semester5/Geosoft2/Code/Notebooks/Sentinel/Data/datacube_2020-06-01_T32UMC_R100.nc\n",
      "Start saving\n",
      "Done saving after 0s\n",
      "File deleted: C:/Users/adria/Desktop/Uni/Semester5/Geosoft2/Code/Notebooks/Sentinel/Data/datacube_2020-06-23_T32ULC_R100.nc\n",
      "File deleted: C:/Users/adria/Desktop/Uni/Semester5/Geosoft2/Code/Notebooks/Sentinel/Data/datacube_2020-06-23_T32UMC_R100.nc\n",
      "Start saving\n",
      "Done saving after 0s\n",
      "File deleted: C:/Users/adria/Desktop/Uni/Semester5/Geosoft2/Code/Notebooks/Sentinel/Data/datacube_2020-06-26_T32ULC_R100.nc\n",
      "File deleted: C:/Users/adria/Desktop/Uni/Semester5/Geosoft2/Code/Notebooks/Sentinel/Data/datacube_2020-06-26_T32UMC_R100.nc\n",
      "Start saving\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-15-8ee7fc477f96>:15: SerializationWarning: saving variable red with floating point data as an integer dtype without any _FillValue to use for NaNs\n",
      "  ds.to_netcdf(directory + name + \".nc\")\n",
      "<ipython-input-15-8ee7fc477f96>:15: SerializationWarning: saving variable nir with floating point data as an integer dtype without any _FillValue to use for NaNs\n",
      "  ds.to_netcdf(directory + name + \".nc\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done saving after 0s\n",
      "File deleted: C:/Users/adria/Desktop/Uni/Semester5/Geosoft2/Code/Notebooks/Sentinel/Data/datacube_2020-06-13_T32UMC_R100.nc\n",
      "Start saving\n",
      "Done saving after 0s\n",
      "File deleted: C:/Users/adria/Desktop/Uni/Semester5/Geosoft2/Code/Notebooks/Sentinel/Data/datacube_2020-06-23_Merged_R100.nc\n",
      "Start saving\n",
      "Done saving after 0s\n",
      "File deleted: C:/Users/adria/Desktop/Uni/Semester5/Geosoft2/Code/Notebooks/Sentinel/Data/datacube_2020-06-26_Merged_R100.nc\n",
      "All cubes merged for 1s\n"
     ]
    }
   ],
   "source": [
    "directory = 'C:/Users/adria/Desktop/Uni/Semester5/Geosoft2/Code/Notebooks/Sentinel/Data/'\n",
    "resolution = 100    #10, 20, 60, 100 possible\n",
    "\n",
    "'''Parameters for the download'''\n",
    "aoi = 'POLYGON((7.52834379254901 52.01238155392252,7.71417925515199 52.01183230436206,7.705255583805303 51.9153349236737,7.521204845259327 51.90983021961716,7.52834379254901 52.01238155392252,7.52834379254901 52.01238155392252))'\n",
    "collectionDate = ('20200601', '20200630')\n",
    "clouds = (0, 30)\n",
    "username = getpass.getpass(\"user: \")\n",
    "password = getpass.getpass(\"password: \")\n",
    "\n",
    "mainSentinel(resolution, directory, collectionDate, aoi, clouds, username, password)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
