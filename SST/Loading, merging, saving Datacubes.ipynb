{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import netCDF4 as net\n",
    "import numpy   as np\n",
    "import pandas  as pd\n",
    "import xarray  as xr\n",
    "import matplotlib.pyplot as plt\n",
    "import shutil\n",
    "import urllib.request as request\n",
    "from contextlib import closing\n",
    "from ftplib import FTP \n",
    "from datetime import datetime\n",
    "import os\n",
    "\n",
    "\n",
    "systempath = \"C:/Users/adria/Desktop/Uni/Semester5/Geosoft2/Code/Notebooks/SST/Data/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_file(year):\n",
    "    '''\n",
    "    Downloads the sst data file for the given year\n",
    "    \n",
    "    Parameters:\n",
    "        year (int): The year the sst is needed\n",
    "   '''\n",
    "    start = datetime.now()\n",
    "    ftp = FTP('ftp.cdc.noaa.gov')\n",
    "    ftp.login()\n",
    "    ftp.cwd('/Projects/Datasets/noaa.oisst.v2.highres/')\n",
    "\n",
    "    files = ftp.nlst()\n",
    "    counter = 0\n",
    "\n",
    "    for file in files:\n",
    "        if file == 'sst.day.mean.'+ str(year)+'.nc':\n",
    "            print(\"Downloading...\" + file)\n",
    "            ftp.retrbinary(\"RETR \" + file, open(systempath + file, 'wb').write)      \n",
    "            ftp.close()\n",
    "            end = datetime.now()\n",
    "            diff = end - start\n",
    "            print('All files downloaded for ' + str(diff.seconds) + 's')\n",
    "        else: counter += 1\n",
    "    \n",
    "        if counter == len(files):\n",
    "            print('No matching dataset found for this year')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_datacubes(ds_merge):\n",
    "    '''\n",
    "    merges datacubes by coordinates\n",
    "    \n",
    "    Parameters:\n",
    "        ds_merge (array): array of datasets to be mearched\n",
    "        \n",
    "    Returns: \n",
    "        ds1 (ds): A single datacube with all merged datacubes\n",
    "        - Error, if no Datacubes given\n",
    "    '''\n",
    "    start = datetime.now()\n",
    "    if len(ds_merge) == 0:\n",
    "        print(\"error\")\n",
    "        return\n",
    "    if len(ds_merge) == 1:\n",
    "        return ds_merge[0]\n",
    "    else:\n",
    "        print('start merging')\n",
    "        ds1 = ds_merge[0]\n",
    "        count = 1\n",
    "        while count < len(ds_merge):\n",
    "            start1 = datetime.now()\n",
    "            ds1 =  xr.combine_by_coords([ds1,ds_merge[count]])\n",
    "            count+=1\n",
    "            print(\"succesfully merged cube nr \"+ str(count)+\" to the base cube \")\n",
    "            end = datetime.now()\n",
    "            diff = end - start1\n",
    "            print('All cubes merged for ' + str(diff.seconds) + 's')\n",
    "        print(\"result: \")\n",
    "        print(ds1)\n",
    "        end = datetime.now()\n",
    "        diff = end - start\n",
    "        print('All cubes merged for ' + str(diff.seconds) + 's')\n",
    "        return ds1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def timeframe(ds,start,end):\n",
    "    '''\n",
    "    Slices Datacube down to given timeframe\n",
    "      \n",
    "    Parameters:\n",
    "        ds (ds): source dataset\n",
    "        start (str): start of the timeframe eg '2018-07-13'\n",
    "        end (str): end of the timeframe eg '2018-08-23'\n",
    "       \n",
    "    Returns:\n",
    "        ds_selected (ds): dataset sliced to timeframe\n",
    "    '''\n",
    "    if start>end:\n",
    "        print(\"start and end of the timeframe do are not compatible!\")\n",
    "    else:    \n",
    "        ds_selected = ds.sel(time = slice(start,end))\n",
    "        #print(ds_selected)\n",
    "        return ds_selected    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def safe_datacube(ds, timeframe):\n",
    "    '''\n",
    "    Saves the Datacube as NetCDF (.nc)\n",
    "      \n",
    "    Parameters:\n",
    "        ds (ds): source dataset\n",
    "        timeframe (str): timeframe eg '2017', '2015_2019'\n",
    "    '''\n",
    "    print(\"start saving\")\n",
    "    if type(timeframe) != str:\n",
    "        timeframe=str(timeframe)\n",
    "    ds.to_netcdf(systempath+ \"sst.day.mean.\"+timeframe+\".nc\")\n",
    "    print(\"done saving\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<xarray.DataArray 'time' (time: 397)>\n",
      "array(['2018-07-01T00:00:00.000000000', '2018-07-02T00:00:00.000000000',\n",
      "       '2018-07-03T00:00:00.000000000', ..., '2019-07-30T00:00:00.000000000',\n",
      "       '2019-07-31T00:00:00.000000000', '2019-08-01T00:00:00.000000000'],\n",
      "      dtype='datetime64[ns]')\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 2018-07-01 2018-07-02 ... 2019-08-01\n",
      "Attributes:\n",
      "    long_name:   Time\n",
      "    delta_t:     0000-00-01 00:00:00\n",
      "    avg_period:  0000-00-01 00:00:00\n",
      "    axis:        T\n"
     ]
    }
   ],
   "source": [
    "# download_file(2018)\n",
    "# download_file(2019)\n",
    "ds_2018 = xr.open_dataset(systempath+\"sst.day.mean.2018.nc\")\n",
    "ds_2019 = xr.open_dataset(systempath+\"sst.day.mean.2019.nc\")\n",
    "ds_merge = [ds_2018,ds_2019]\n",
    "# ds_2018_2019 = merge_datacubes(ds_merge)\n",
    "ds_2018_2019 = xr.open_dataset(systempath+\"sst.day.mean.2018-2019.nc\")\n",
    "ds_sliced = timeframe(ds_2018_2019,'2018-07-01','2019-08-01')\n",
    "print(ds_sliced.time)\n",
    "# safe_datacube(ds_2018_2019,\"201819\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<xarray.Dataset>\n",
      "Dimensions:  (lat: 720, lon: 1440, time: 365)\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 2018-01-01 2018-01-02 ... 2018-12-31\n",
      "  * lat      (lat) float32 -89.88 -89.62 -89.38 -89.12 ... 89.38 89.62 89.88\n",
      "  * lon      (lon) float32 0.125 0.375 0.625 0.875 ... 359.1 359.4 359.6 359.9\n",
      "Data variables:\n",
      "    sst      (time, lat, lon) float32 ...\n",
      "Attributes:\n",
      "    Conventions:    CF-1.5\n",
      "    title:          NOAA/NCEI 1/4 Degree Daily Optimum Interpolation Sea Surf...\n",
      "    institution:    NOAA/National Centers for Environmental Information\n",
      "    source:         NOAA/NCEI https://www.ncei.noaa.gov/data/sea-surface-temp...\n",
      "    References:     https://www.psl.noaa.gov/data/gridded/data.noaa.oisst.v2....\n",
      "    dataset_title:  NOAA Daily Optimum Interpolation Sea Surface Temperature\n",
      "    version:        Version 2.1\n",
      "    comment:        Reynolds, et al.(2007) Daily High-Resolution-Blended Anal...\n"
     ]
    }
   ],
   "source": [
    "print(ds_2018)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
