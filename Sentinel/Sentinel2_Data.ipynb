{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@author Adrian Spork https://github.com/A-Spork\n",
    "#@author Tatjana Melina Walter https://github.com/jana2308walter\n",
    "#@author Maximilian Busch https://github.com/mabu1994"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentinelsat import SentinelAPI, read_geojson, geojson_to_wkt\n",
    "import getpass\n",
    "import xarray as xr\n",
    "import rasterio as rio\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import shutil\n",
    "from time import sleep\n",
    "import stat\n",
    "import io\n",
    "from rasterio.enums import Resampling\n",
    "import netCDF4 as nc\n",
    "from datetime import datetime\n",
    "from zipfile import ZipFile\n",
    "\n",
    "class NoPath(Exception):\n",
    "    def init(self, message):\n",
    "        self.message = message\n",
    "    pass\n",
    "\n",
    "class NoResolution(Exception):\n",
    "    def init(self, message):\n",
    "        self.message = message\n",
    "    pass\n",
    "\n",
    "class NoSafeFileError(Exception):\n",
    "    def init(self,message):\n",
    "        self.message = message\n",
    "    pass "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def downloadingData(aoi, collectionDate, plName, prLevel, clouds, username, password, directory):\n",
    "    '''\n",
    "    Downloads the Sentinel2 - Data with the given parameters\n",
    "\n",
    "    Parameters:\n",
    "        aoi (str): The type and the coordinates of the area of interest\n",
    "        collectionDate datetime 64[ns]): The date of the data\n",
    "        plName (str): The name of the platform\n",
    "        prLevel (str): The name of the process\n",
    "        clouds (tuple of ints): Min and max of cloudcoverpercentage\n",
    "        username (str): The username of the Copernicus SciHub\n",
    "        password (str): The password of the Copernicus SciHub\n",
    "        directory (str): Pathlike string to the directory\n",
    "    '''\n",
    "    \n",
    "    api = SentinelAPI(username, password, 'https://scihub.copernicus.eu/dhus')\n",
    "    \n",
    "    '''Choosing the data with bounding box (footprint), date, platformname, processinglevel and cloudcoverpercentage'''\n",
    "    products = api.query(aoi, date = collectionDate, platformname = plName, processinglevel = prLevel, cloudcoverpercentage = clouds)\n",
    "\n",
    "    '''Downloads the choosen files from Scihub'''\n",
    "    if len(products)==0:\n",
    "        raise Exception(\"No data for this params\")\n",
    "    print(\"Start downloading \" + str(len(products)) + \" product(s)\")\n",
    "    api.download_all(products, directory, max_attempts = 10, checksum = True)\n",
    "    print(\"All necassary downloads done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unzipping(filename, directory):\n",
    "    '''\n",
    "    Unzips the file with the given filename\n",
    "    Parameter:\n",
    "        filename(str): Name of the .zip file\n",
    "        directory (str): Pathlike string to the directory\n",
    "    '''\n",
    "    with ZipFile(os.path.join(directory, filename), 'r') as zipObj:\n",
    "        zipObj.extractall(directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unzip(directory):\n",
    "    '''\n",
    "    Unzips and deletes the .zip in the given directory\n",
    "\n",
    "    Parameters:\n",
    "        directory (str): Pathlike string to the directory\n",
    "    '''\n",
    "\n",
    "    for filename in os.listdir(directory):\n",
    "        if filename.endswith(\".zip\"):\n",
    "            if(filename[39:41]!=\"32\"):\n",
    "                print(\"CRS not supported! Only EPSG:32632 supported\")\n",
    "                delete(os.path.join(directory,filename))\n",
    "            else:\n",
    "                unzipping(filename, directory)\n",
    "                delete(os.path.join(directory, filename))\n",
    "                continue\n",
    "        else:\n",
    "            continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def delete(path):\n",
    "    '''\n",
    "    Deletes the file/directory with the given path\n",
    "    Parameters:\n",
    "        path (str): Path to the file/directory\n",
    "    '''\n",
    "    try: \n",
    "        os.remove(path)\n",
    "        print(\"File was deleted\")\n",
    "    except FileNotFoundError:\n",
    "        raise NoPath (\"No file in this path\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extractBands(filename, resolution, directory):\n",
    "    '''\n",
    "    Extracts bandpaths from the given .SAFE file\n",
    "    Parameters:\n",
    "        filename (str): Sentinel .SAFE file\n",
    "        resolution (int): The resolution the datacube should have\n",
    "        directory (str): Pathlike string to the directory\n",
    "    Returns:\n",
    "        bandPaths (str[]): An array of the paths for the red and nir band\n",
    "    '''\n",
    "\n",
    "    try:\n",
    "        lTwoA = os.listdir(os.path.join(directory, filename, \"GRANULE\"))\n",
    "        if resolution == 10:\n",
    "            bandName = os.listdir (os.path.join(directory, filename, \"GRANULE\", str(lTwoA[0]), \"IMG_DATA\", \"R10m\"))\n",
    "            pathRed = os.path.join(directory, filename, \"GRANULE\", str(lTwoA[0]), \"IMG_DATA\", \"R10m\", str(bandName[3]))\n",
    "            pathNIR = os.path.join(directory, filename, \"GRANULE\", str(lTwoA[0]), \"IMG_DATA\", \"R10m\", str(bandName[4]))\n",
    "            bandPaths = [pathRed, pathNIR]\n",
    "\n",
    "        elif resolution == 20:\n",
    "            bandName = os.listdir (os.path.join(directory, filename, \"GRANULE\", str(lTwoA[0]), \"IMG_DATA\", \"R20m\"))\n",
    "            pathRed = os.path.join(directory, filename, \"GRANULE\", str(lTwoA[0]), \"IMG_DATA\", \"R20m\", str(bandName[3]))\n",
    "            pathNIR = os.path.join(directory, filename, \"GRANULE\", str(lTwoA[0]), \"IMG_DATA\", \"R20m\", str(bandName[9]))\n",
    "            bandPaths = [pathRed, pathNIR]\n",
    "\n",
    "        elif resolution == 60:\n",
    "            bandName = os.listdir (os.path.join(directory, filename, \"GRANULE\", str(lTwoA[0]), \"IMG_DATA\", \"R60m\"))\n",
    "            pathRed = os.path.join(directory, filename, \"GRANULE\", str(lTwoA[0]), \"IMG_DATA\", \"R60m\", str(bandName[4]))\n",
    "            pathNIR = os.path.join(directory, filename, \"GRANULE\", str(lTwoA[0]), \"IMG_DATA\", \"R60m\", str(bandName[11]))\n",
    "            bandPaths = [pathRed, pathNIR]\n",
    "\n",
    "        elif resolution == 100:\n",
    "            bandName = os.listdir (os.path.join(directory, filename, \"GRANULE\", str(lTwoA[0]), \"IMG_DATA\", \"R20m\"))\n",
    "            pathRed = os.path.join(directory, filename, \"GRANULE\", str(lTwoA[0]), \"IMG_DATA\", \"R20m\", str(bandName[3]))\n",
    "            pathNIR = os.path.join(directory, filename, \"GRANULE\", str(lTwoA[0]), \"IMG_DATA\", \"R20m\", str(bandName[9]))\n",
    "            bandPaths = [pathRed, pathNIR]\n",
    "\n",
    "        else:\n",
    "               raise NoResolution(\"Invalid Resolution, try 10, 20, 60 or 100\")\n",
    "    except FileNotFoundError:\n",
    "        raise NoPath(\"No file in this path\")\n",
    "    return bandPaths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadBand (bandpath, date, tile, resolution, clouds, plName, prLevel, directory):\n",
    "    '''\n",
    "    Opens and reads the red and nir band, saves them as NetCDF file\n",
    "    Parameters:\n",
    "        bandPaths (str[]): Array with the paths to the red and nir band\n",
    "        date (datetime 64[ns]): The collection date (\"2020-12-31\")\n",
    "        tile (str): Bounding box of coordinates defined by Sentinel\n",
    "        resolution (int): The resolution of the dataset\n",
    "        clouds (tuple of ints): Min and max of cloudcoverpercentage\n",
    "        plName (str): The name of the platform\n",
    "        prLevel (str): The level of the process\n",
    "        directory (str): Pathlike string to the directory\n",
    "    Returns:\n",
    "        dataset (xArray dataset): The result dataset as xArray dataset\n",
    "    '''\n",
    "    \n",
    "    \n",
    "    b4 = rio.open(bandpath[0])\n",
    "    b8 = rio.open(bandpath[1])\n",
    "    red = b4.read()\n",
    "    nir = b8.read()\n",
    "\n",
    "    if resolution == 10:\n",
    "        res = 1830 * 3 * 2\n",
    "    elif resolution == 20:\n",
    "        res = 1830 * 3\n",
    "    elif resolution == 60:\n",
    "        res = 1830\n",
    "    elif resolution == 100:\n",
    "        res = 1098\n",
    "    else:\n",
    "        raise NoResolution(\"Invalid Resolution, try 10, 20, 60 or 100\")\n",
    "\n",
    "    j = res - 1\n",
    "    i = 0\n",
    "    lat = [0] * res\n",
    "    lon = [0] * res\n",
    "    while j >= 0:\n",
    "        lon[i] = b4.bounds.left + i * resolution\n",
    "        lat[i] = b4.bounds.bottom + j * resolution\n",
    "        i = i + 1\n",
    "        j = j - 1\n",
    "\n",
    "    time = pd.date_range(date, periods = 1)\n",
    "\n",
    "    if resolution == 100:\n",
    "        upscale_factor = (1/5)\n",
    "        nir = b8.read(\n",
    "                out_shape = (\n",
    "                    b8.count,\n",
    "                    int(b8.height * upscale_factor),\n",
    "                    int(b8.width * upscale_factor)\n",
    "                ),\n",
    "                resampling = Resampling.bilinear\n",
    "        )\n",
    "        transform = b8.transform * b8.transform.scale(\n",
    "            (b8.width / nir.shape[-1]),\n",
    "            (b8.height / nir.shape[-2])\n",
    "        )\n",
    "        red = b4.read(\n",
    "            out_shape = (\n",
    "                b4.count,\n",
    "                int(b4.height * upscale_factor),\n",
    "                int(b4.width * upscale_factor)\n",
    "            ),\n",
    "            resampling = Resampling.bilinear\n",
    "        )\n",
    "\n",
    "        transform = b4.transform * b4.transform.scale(\n",
    "            (b4.width / red.shape[-1]),\n",
    "            (b4.height / red.shape[-2])\n",
    "        )\n",
    "\n",
    "    dataset = xr.Dataset(\n",
    "        {\n",
    "            \"red\": ([\"time\",\"lat\", \"lon\"], red),\n",
    "            \"nir\": ([\"time\",\"lat\", \"lon\"], nir)\n",
    "        },\n",
    "        coords = dict(\n",
    "            time = time,\n",
    "            lat = ([\"lat\"], lat),\n",
    "            lon = ([\"lon\"], lon),\n",
    "        ),\n",
    "        attrs = dict(\n",
    "            platform = plName,\n",
    "            processingLevel = prLevel,\n",
    "            source = \"https://scihub.copernicus.eu/dhus\",\n",
    "            resolution = str(resolution) + \" x \" + str(resolution) + \" m\"\n",
    "        ),\n",
    "    )\n",
    "\n",
    "    dataset.to_netcdf(directory + \"datacube_\" + str(date) + \"_\" + str(tile) + \"_R\" + str(resolution) + \".nc\", 'w', format = 'NETCDF4')\n",
    "    b4.close()\n",
    "    b8.close()\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getDate(filename):\n",
    "    '''\n",
    "    Extracts the Date out of the Sentinelfilename\n",
    "    Parameters:\n",
    "        filename (str): Name of the file\n",
    "    Returns:\n",
    "        (str): Date of the File (\"2020-12-31\")\n",
    "    '''\n",
    "\n",
    "    return filename[11:15] + \"-\" + filename[15:17] + \"-\" + filename[17:19]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getTile(filename):\n",
    "    '''\n",
    "    Extracts the UTM-tile of the Sentinelfilename\n",
    "    Parameters:\n",
    "        filename (str): Name of the file\n",
    "    Returns:\n",
    "        (str): UTM-tile of the File (\"31UMC\")\n",
    "    '''\n",
    "    return filename[38:44]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def on_rm_error(func, path, exc_info):\n",
    "    '''\n",
    "    Unlinks a read-only file\n",
    "    '''\n",
    "\n",
    "    os.chmod(path, stat.S_IWRITE)\n",
    "    os.unlink(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def buildCube(directory, resolution, clouds, plName, prLevel):\n",
    "    '''\n",
    "    Builds a datacube in the given directory with coords, time as dimensions and the bands as datavariables\n",
    "    Parameters:\n",
    "        directory (str): Pathlike string to the directory\n",
    "        resolution (int): The resolution of the dataset\n",
    "        clouds (tuple of ints): Min and max of cloudcoverpercentage\n",
    "        plName (str): The name of the platform\n",
    "        prLevel (str): The level of the process\n",
    "    '''\n",
    "    \n",
    "    i = 0\n",
    "    for filename in os.listdir(directory):\n",
    "        if filename.endswith(\".SAFE\"):\n",
    "            i = i + 1\n",
    "    if i == 0:\n",
    "        raise NoSafeFileError (\"In this directory is no SAFE file to build a cube\")\n",
    "    for filename in os.listdir(directory):\n",
    "        if filename.endswith(\".SAFE\"):\n",
    "            bandPath = extractBands(os.path.join(directory, filename), resolution, directory)\n",
    "            band = loadBand(bandPath, getDate(filename), getTile(filename), resolution, clouds, plName, prLevel, directory)\n",
    "            shutil.rmtree(os.path.join(directory, filename), onerror = on_rm_error)\n",
    "            continue\n",
    "        else:\n",
    "            continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "def merge_Sentinel(directory):\n",
    "    '''\n",
    "    Merges datacubes by coordinates and time\n",
    "\n",
    "    Parameters:\n",
    "        directory (str): Pathlike string where Data is stored\n",
    "    '''\n",
    "\n",
    "    start = datetime.now()\n",
    "    count1 = 0\n",
    "\n",
    "    files = os.listdir(directory)\n",
    "    for nc in files:\n",
    "        if nc.endswith(\".nc\"):\n",
    "            continue\n",
    "        else:\n",
    "            raise TypeError(\"Wrong file in directory\")\n",
    "    if len(files) == 0:\n",
    "        raise FileNotFoundError(\"Directory empty\")\n",
    "    elif len(files) == 1:\n",
    "        print(\"Only one file in directory\")\n",
    "        os.rename(directory + (os.listdir(directory)[0]), directory + \"merged_cube.nc\")\n",
    "        return\n",
    "    else:\n",
    "        print('Start merging')\n",
    "        for file1 in files:\n",
    "            if count1 == len(files):\n",
    "                return\n",
    "            for file2 in files:\n",
    "                count2 = 0\n",
    "                file1Date = file1[9:19]\n",
    "                file1Tile = file1[20:26]\n",
    "                file1Res = file1[27:31]\n",
    "                file2Date = file2[9:19]\n",
    "                file2Tile = file2[20:26]\n",
    "                file2Res = file2[27:31]\n",
    "                if file1[21:23] == \"31\":\n",
    "                    delete(os.path.join(directory,file1))\n",
    "                elif file2[21:23] == \"31\":\n",
    "                    delete(os.path.join(directory,file2))\n",
    "                elif file1Date == file2Date and file1Tile == file2Tile and file1Res == file2Res:\n",
    "                    continue\n",
    "                elif file1Date == file2Date and file1Tile == \"T32ULC\" and file2Tile == \"T32UMC\" and file1Res == file2Res:\n",
    "                    fileLeft = xr.open_dataset(os.path.join(directory, file1))\n",
    "                    fileRight = xr.open_dataset(os.path.join(directory, file2))\n",
    "                    merge_coords(fileLeft, fileRight, file1[0:20] + \"Merged\" + file1[26:31], directory)\n",
    "                    fileLeft.close()\n",
    "                    fileRight.close()\n",
    "                    delete(os.path.join(directory, file1))\n",
    "                    delete(os.path.join(directory, file2))                   \n",
    "\n",
    "    files = os.listdir(directory)\n",
    "    while len(os.listdir(directory)) > 1:\n",
    "        files = os.listdir(directory)\n",
    "        file1 = xr.open_dataset(os.path.join(directory, files[0]))\n",
    "        file2 = xr.open_dataset(os.path.join(directory, files[1]))\n",
    "        merge_time(file1, file2, files[0][0:31], directory)\n",
    "        file1.close()\n",
    "        file2.close()\n",
    "        delete(os.path.join(directory, files[1]))\n",
    "    end = datetime.now()\n",
    "    diff = end - start\n",
    "    print('All cubes merged for ' + str(diff.seconds) + 's')\n",
    "    os.rename(directory + (os.listdir(directory)[0]), directory + \"merged_cube.nc\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def timeframe(ds, start, end):\n",
    "    '''\n",
    "    Slices Datacube down to given timeframe\n",
    "    Parameters:\n",
    "        ds (xArray Dataset): Sourcedataset\n",
    "        start (str): Start of the timeframe eg '2018-07-13'\n",
    "        end (str): End of the timeframe eg '2018-08-23'\n",
    "    Returns:\n",
    "        ds_selected (xArray Dataset): Dataset sliced to timeframe\n",
    "    '''\n",
    "\n",
    "    if start > end:\n",
    "        print(\"start and end of the timeframe are not compatible!\")\n",
    "    else:\n",
    "        ds_selected = ds.sel(time = slice(start, end))\n",
    "        return ds_selected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def safe_datacube(ds, name, directory):\n",
    "    '''\n",
    "    Saves the Datacube as NetCDF (.nc)\n",
    "    Parameters:\n",
    "        ds (xArray Dataset): Sourcedataset\n",
    "        name (str): Name eg '2017', '2015_2019'\n",
    "        directory (str): Pathlike string to the directory\n",
    "    '''\n",
    "\n",
    "    print(\"Start saving\")\n",
    "    start = datetime.now()\n",
    "    ds.to_netcdf(directory + name + \".nc\")\n",
    "    diff = datetime.now() - start\n",
    "    print(\"Done saving after \"+ str(diff.seconds) + 's')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_coords(ds_left, ds_right, name, directory):\n",
    "    '''\n",
    "    Merges two datasets by coordinates\n",
    "\n",
    "    Parameters:\n",
    "        ds_left (xArray dataset): Dataset to be merged\n",
    "        ds_right (xArray dataset): Dataset to be merged\n",
    "        name (str): Name of the new dataset\n",
    "        directory (str): Pathlike string to the directory\n",
    "    '''\n",
    "\n",
    "    ds_selected = ds_left.sel(lon = slice(ds_left.lon[0], ds_right.lon[0]))\n",
    "    ds_merge = [ds_selected, ds_right]\n",
    "    merged = xr.combine_by_coords(ds_merge)\n",
    "    safe_datacube(merged, name, directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_time(ds1, ds2, name, directory):\n",
    "    '''\n",
    "    Merges two datasets by time\n",
    "    Parameters:\n",
    "        ds1 (xArray dataset): Dataset to be merged\n",
    "        ds2 (xArray dataset): Dataset to be merged\n",
    "        name (str): Name of the new dataset\n",
    "        directory (str): Pathlike string to the directory\n",
    "    '''\n",
    "\n",
    "    res = xr.combine_by_coords([ds1, ds2])\n",
    "    ds1.close()\n",
    "    ds2.close()\n",
    "    safe_datacube(res, name, directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def slice_lat(ds, lat_left, lat_right):\n",
    "    '''\n",
    "    Slices a given dataset to given latitude bounds\n",
    "    Parameters:\n",
    "        ds (xArray Dataset): Dataset to be sliced\n",
    "        lat_left (float): Left latitude bound\n",
    "        lat_right (float): Right latitude bound\n",
    "    Returns:\n",
    "        ds (xArray Dataset): Sliced dataset\n",
    "    '''\n",
    "\n",
    "    ds_selected = ds.sel(lat = slice(lat_left, lat_right))\n",
    "    return ds_selected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def slice_lon(ds, lon_left, lon_right):\n",
    "    '''\n",
    "    Slices a given dataset to given longitude bounds\n",
    "    Parameters:\n",
    "        ds (xArray Dataset): Dataset to be sliced\n",
    "        lon_left (float): Left longitude bound\n",
    "        lon_right (float): Right longitude bound\n",
    "    Returns:\n",
    "        ds (xArray Dataset): Sliced dataset\n",
    "    '''\n",
    "\n",
    "    ds_selected = ds.sel(lon = slice(lon_left, lon_right))\n",
    "    return ds_selected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def slice_coords(ds, lon_left, lon_right, lat_left, lat_right):\n",
    "    '''\n",
    "    Slices a dataset to a given slice\n",
    "    Parameters:\n",
    "        ds (xArray Dataset): Dataset to be sliced\n",
    "        lon_left (float): Left bound for longitude\n",
    "        lon_right (float): Right bound for longitude\n",
    "        lat_left (float): Left bound for latitude\n",
    "        lat_right (float): Right bound for latitude\n",
    "    Returns:\n",
    "        ds (xArray Dataset): Sliced dataset\n",
    "    '''\n",
    "\n",
    "    ds_selected = slice_lon(ds, lon_left, lon_right)\n",
    "    return slice_lat(ds_selected, lat_left, lat_right)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mainSentinel(resolution, directory, collectionDate, aoi, clouds, username, password):\n",
    "    '''\n",
    "    Downloads, unzips, collects and merges Sentinel2 Satelliteimages to a single netCDF4 datacube\n",
    "\n",
    "    Parameters:\n",
    "        resolution (int): Resolution of the satelite image\n",
    "        directory (str): Pathlike string to the workdirectory\n",
    "        collectionDate (tuple of datetime 64[ns]): Start and end of the timeframe\n",
    "        aoi (POLYGON): Area of interest\n",
    "        clouds (tuple of ints): Min and max of cloudcoverpercentage\n",
    "        username (str): Uername for the Copernicus Open Acess Hub\n",
    "        password (str): Password for the Copernicus Open Acess Hub\n",
    "    '''\n",
    "    if collectionDate[0]==collectionDate[1]:\n",
    "        raise Exception(\"Start and end of collection can not be identical\")\n",
    "    plName = 'Sentinel-2'\n",
    "    prLevel = 'Level-2A'\n",
    "    downloadingData (aoi, collectionDate, plName, prLevel, clouds, username, password, directory)\n",
    "    unzip(directory)\n",
    "    buildCube(directory, resolution, clouds, plName, prLevel)\n",
    "    merge_Sentinel(directory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user: ········\n",
      "password: ········\n"
     ]
    }
   ],
   "source": [
    "username = getpass.getpass(\"user: \")\n",
    "password = getpass.getpass(\"password: \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start merging\n",
      "Start saving\n",
      "Done saving after 0s\n",
      "File deleted: F:/Data_Sentinel/WorkDir/datacube_2020-06-01_T32ULC_R100.nc\n",
      "File deleted: F:/Data_Sentinel/WorkDir/datacube_2020-06-01_T32UMC_R100.nc\n",
      "Start saving\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-15-1b6e65e04f83>:13: SerializationWarning: saving variable red with floating point data as an integer dtype without any _FillValue to use for NaNs\n",
      "  ds.to_netcdf(directory + name + \".nc\")\n",
      "<ipython-input-15-1b6e65e04f83>:13: SerializationWarning: saving variable nir with floating point data as an integer dtype without any _FillValue to use for NaNs\n",
      "  ds.to_netcdf(directory + name + \".nc\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done saving after 1s\n",
      "File deleted: F:/Data_Sentinel/WorkDir/datacube_2020-06-13_T32UMC_R100.nc\n",
      "All cubes merged for 1s\n"
     ]
    }
   ],
   "source": [
    "directory = 'F:/Data_Sentinel/WorkDir/'\n",
    "resolution = 100    #10, 20, 60, 100 possible\n",
    "\n",
    "'''Parameters for the download'''\n",
    "aoi = 'POLYGON((7.52834379254901 52.01238155392252,7.71417925515199 52.01183230436206,7.705255583805303 51.9153349236737,7.521204845259327 51.90983021961716,7.52834379254901 52.01238155392252,7.52834379254901 52.01238155392252))'\n",
    "collectionDate = ('2020-06-01T00:00:00Z', '2020-06-22T23:59:59Z')\n",
    "clouds = (0, 30)\n",
    "\n",
    "\n",
    "mainSentinel(resolution, directory, collectionDate, aoi, clouds, username, password)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
